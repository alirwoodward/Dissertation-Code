{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab52a016-25e0-475e-9ee5-294820ad08d3",
   "metadata": {},
   "source": [
    "# Load CSV file and enter pair you want to observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77caee-3582-4a32-8cdd-2ba80a3971a9",
   "metadata": {},
   "source": [
    "Tuesday Pair Combinations (name, data column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe25573-8e60-436c-94db-69b7e8f1747c",
   "metadata": {},
   "source": [
    "P6GR, 113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbcb971-dc4c-40b7-af60-b85796d0df6c",
   "metadata": {},
   "source": [
    "P2CR, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a431999-54a7-422f-ab7a-6b270d576231",
   "metadata": {},
   "source": [
    "P1ER, 139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa47bb-9fb1-43a9-92f4-47b0b0f65f79",
   "metadata": {},
   "source": [
    "P5FR, 206"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecb864-6675-4c83-839d-005bd77edb6b",
   "metadata": {},
   "source": [
    "P3HR, 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63823574-2f21-46d7-be16-618e2b2ab773",
   "metadata": {},
   "source": [
    "Friday Pair Combinations (name, data column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256b776-70e0-482d-bac4-f31b0d193d1e",
   "metadata": {},
   "source": [
    "P7CR, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcaf4c-166d-426e-81bb-7051be9bade3",
   "metadata": {},
   "source": [
    "P11ER, 83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ff41c-2c95-482b-9415-9c97db68e1c5",
   "metadata": {},
   "source": [
    "P8IR, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ca3cf5-b6ae-4181-b800-2c59b8174e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the data\n",
    "# change this line depending on tuesday or friday data\n",
    "df = pd.read_csv('tues_axw_video_data.csv')\n",
    "#df = pd.read_csv('fri_axw_video_data.csv')\n",
    "\n",
    "# Extract the time and synchrony data for your pair \n",
    "time_data = df['Time']\n",
    "\n",
    "#enter the column number for the pair you want to look at here\n",
    "pair = df['224']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e748eb-eb52-4e72-985c-992a3c07fe71",
   "metadata": {},
   "source": [
    "# Video with Overlayed Heat Map for one pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd94cb2-46da-491f-9699-ba76cc40c170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@581.277] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 545438.342211 ms\n",
      "[ WARN:0@581.278] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 545440.369843 ms\n",
      "[ WARN:0@581.278] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 545440.406592 ms\n",
      "[ WARN:0@581.278] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 545440.419217 ms\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x10e9f4590] moov atom not found\n",
      "Processing video: 406945it [1:24:38, 80.12it/s]                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply smoothing\n",
    "smoothed_sync = gaussian_filter1d(pair, sigma=5)\n",
    "\n",
    "# Create custom colormap\n",
    "colors = ['blue', 'cyan', 'yellow', 'red']\n",
    "n_bins = 100\n",
    "cmap = LinearSegmentedColormap.from_list('cool_to_warm', colors, N=n_bins)\n",
    "\n",
    "# Open the video\n",
    "# change this line depending on day\n",
    "video = cv2.VideoCapture('TuesdayVideo.mov')\n",
    "#video = cv2.VideoCapture('FridayVideo.mov')\n",
    "\n",
    "# Get video properties\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Set up the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# name your output file\n",
    "#change depending on pair\n",
    "out = cv2.VideoWriter('P3HR.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Heat map dimensions and position\n",
    "hm_width, hm_height = 100, 100\n",
    "hm_x, hm_y = width - hm_width - 10, height - hm_height - 10\n",
    "\n",
    "# Set up progress bar\n",
    "pbar = tqdm(total=total_frames, desc=\"Processing video\")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = frame_count / fps\n",
    "    if current_time >= time_data.iloc[-1]:\n",
    "        break\n",
    "\n",
    "    # Find the closest time index\n",
    "    time_index = np.searchsorted(time_data, current_time)\n",
    "    \n",
    "    # Get the current synchrony value\n",
    "    current_sync = smoothed_sync[time_index]\n",
    "\n",
    "    # Create heat map\n",
    "    heatmap = np.full((hm_height, hm_width, 3), current_sync)\n",
    "    heatmap = (cmap(heatmap[:,:,0])[:,:,:3] * 255).astype(np.uint8)\n",
    "\n",
    "    # Add heat map to frame\n",
    "    frame[hm_y:hm_y+hm_height, hm_x:hm_x+hm_width] = heatmap\n",
    "\n",
    "    # Add time text below heat map\n",
    "    cv2.putText(frame, f\"Time: {current_time:.2f}s\", (hm_x, hm_y+hm_height+20), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "    # Add synchrony value above heat map\n",
    "    cv2.putText(frame, f\"Sync: {current_sync:.2f}\", (hm_x, hm_y-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Close progress bar\n",
    "pbar.close()\n",
    "\n",
    "print(\"Video processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c95bb-620b-46cb-aed4-babe02f4c998",
   "metadata": {},
   "source": [
    "# All pairs together with heat map overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92ad54-f63e-43d9-b6d3-d05fefaed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data Tuesday\n",
    "#df = pd.read_csv('axw_video_data.csv')\n",
    "\n",
    "# Load the data Friday\n",
    "df = pd.read_csv('fri_axw_video_data.csv')\n",
    "\n",
    "# Extract the time data\n",
    "time_data = df['Time']\n",
    "\n",
    "# List of pairs tuesday\n",
    "#pairs = ['113', '100', '139', '206', '224']\n",
    "\n",
    "#List of pairs friday\n",
    "pairs = ['100', '83', '48']\n",
    "\n",
    "# Custom titles tuesday\n",
    "#titles = ['P6GR', 'P2CR', 'P1ER', 'P5FR', 'P3HR']\n",
    "\n",
    "# Custom titles friday\n",
    "titles = ['P7CR', 'P11ER', 'P8IR']\n",
    "\n",
    "\n",
    "# Apply smoothing to each pair\n",
    "smoothed_syncs = {pair: gaussian_filter1d(df[pair], sigma=5) for pair in pairs}\n",
    "\n",
    "# Create the custom colormap\n",
    "colors = ['blue', 'cyan', 'yellow', 'red']\n",
    "n_bins = 100\n",
    "cmap = LinearSegmentedColormap.from_list('cool_to_warm', colors, N=n_bins)\n",
    "\n",
    "# Open the video\n",
    "#video = cv2.VideoCapture('TuesdayVideo.mov')\n",
    "video = cv2.VideoCapture('FridayVideo.mov')\n",
    "\n",
    "\n",
    "# Get video properties\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Set up the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#out = cv2.VideoWriter('allTuesday.mp4', fourcc, fps, (width, height))\n",
    "out = cv2.VideoWriter('allFriday.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Heat map dimensions and position\n",
    "hm_width, hm_height = 100, 100\n",
    "hm_y = 50  # Adjusted position for better visibility\n",
    "\n",
    "# Set up progress bar\n",
    "pbar = tqdm(total=total_frames, desc=\"Processing video\")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = frame_count / fps\n",
    "    if current_time >= time_data.iloc[-1]:\n",
    "        break\n",
    "\n",
    "    # Find the closest time index\n",
    "    time_index = np.searchsorted(time_data, current_time)\n",
    "    \n",
    "    # Process each pair\n",
    "    for i, (pair, title) in enumerate(zip(pairs, titles)):\n",
    "        current_sync = smoothed_syncs[pair][time_index]\n",
    "\n",
    "        # Create heat map\n",
    "        heatmap = np.full((hm_height, hm_width, 3), current_sync)\n",
    "        heatmap = (cmap(heatmap[:,:,0])[:,:,:3] * 255).astype(np.uint8)\n",
    "\n",
    "        # Calculate x position for each heatmap\n",
    "        hm_x = 10 + i * (hm_width + 10)\n",
    "\n",
    "        # Add heat map to frame\n",
    "        frame[hm_y:hm_y+hm_height, hm_x:hm_x+hm_width] = heatmap\n",
    "\n",
    "        # Add custom title above each heat map\n",
    "        cv2.putText(frame, title, (hm_x, hm_y-15), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "        \n",
    "        # Add synchrony value below each heat map\n",
    "        cv2.putText(frame, f\"{current_sync:.2f}\", (hm_x, hm_y+hm_height+20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "video.release()\n",
    "out.release()\n",
    "\n",
    "# Close progress bar\n",
    "pbar.close()\n",
    "\n",
    "print(\"Video processing complete with custom titles and synchrony values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c42a6f-d249-40d2-a00f-29e7fcbb8a4c",
   "metadata": {},
   "source": [
    "# All other static visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129f8cdf-ff10-4f79-ae00-ce02a7fb634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair P6GR Segments\n",
    "# change these depending on what pair you're looking at\n",
    "\n",
    "segments = [\n",
    "    (0, 435),     # 00:00:00 - 00:07:15\n",
    "    (435, 525),  # 00:07:15 - 00:08:45\n",
    "    (525, 593), # 00:08:45 - 00:09:53 \n",
    "    (593, 695), # 00:09:53 - 00:11:35 IN\n",
    "    (695, 900), # 00:11:35 - 00:15:00\n",
    "    (900, 1207), # 00:15:00 - 00:20:07\n",
    "    (1207, 1405), # 00:20:07- 00:23:25\n",
    "    (1405, 1525), # 00:23:25 - 00:25:25 IN\n",
    "    (1525, 1640), # 00:25:25- 00:27:20\n",
    "    (1640, 1917), # 00:27:20 - 00:31:57\n",
    "    (1917, 1965), # 00:31:57 -  00:32:45\n",
    "    (1965, 2070), # 00:32:45 - 00:34:30 IN\n",
    "    (2070, 2505), # 00:34:30 -  00:41:45\n",
    "    (2505, 2893), # 00:41:45 - 00:48:13\n",
    "    (2893, 3202), # 00:48:13 - 00:53:22\n",
    "    (3202, 3285), # 00:53:22 - 00:54:45 IN\n",
    "    (3285, 3378), # 00:54:45 - 00:56:18\n",
    "    (3378, 3722), # 00:56:18 - 01:02:02\n",
    "    (3722, 3860), # 01:02:02 - 01:04:20\n",
    "    (3860, 3955), # 01:04:20 - 01:05:55 IN\n",
    "    (3955, 4363), # 01:05:55 - 01:12:43\n",
    "    (4363, 4646), # 01:12:43 - 01:17:26\n",
    "    (4646, 5396), # 01:17:26 - 01:29:56\n",
    "    (5396, 5493) # 01:29:56 - 01:31:33\n",
    "]\n",
    "\n",
    "segment_labels = [\n",
    "    'Intro (Hello)',\n",
    "    'Group Activity #1',\n",
    "    'Game #1 (out)',\n",
    "    'Game #1 (in)',\n",
    "    'Game #1 (out)',\n",
    "    'Group Activity #2',\n",
    "    'Game #2 (out)',\n",
    "    'Game #2 (in)',\n",
    "    'Game #2 (out)',\n",
    "    'Group Activity #3',\n",
    "    'Game #3 (out)',\n",
    "    'Game #3 (in)',\n",
    "    'Game #3 (out)',\n",
    "    'Individual Activity #1',\n",
    "    'Game #4 (out)',\n",
    "    'Game #4 (in)',\n",
    "    'Game #4 (out)',\n",
    "    'Group Activity #4',\n",
    "    'Game #5 (out)',\n",
    "    'Game #5 (in)',\n",
    "    'Game #5 (out)',\n",
    "    'Group Activity #5',\n",
    "    'Individual Activity #2',\n",
    "    'Outro (Goodbye)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc9908-8567-4860-8bf2-6fd32dc70fdd",
   "metadata": {},
   "source": [
    "# Synchrony Plot and Key Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c744c4b-ff21-4c31-bf6d-fa34cf72ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('tues_axw_video_data.csv')\n",
    "\n",
    "def analyze_and_create_table_with_segments(df, column, segments, exclude_last_minutes=15, interval_seconds=30):\n",
    "    # Convert Time to seconds if it's not already\n",
    "    if df['Time'].max() < 1000:  # Assuming if max is less than 1000, it's in minutes\n",
    "        df['Time'] = df['Time'] * 60\n",
    "\n",
    "    # Calculate the total duration and the cutoff time\n",
    "    total_duration = df['Time'].max()\n",
    "    cutoff_time = total_duration - (exclude_last_minutes * 60)\n",
    "\n",
    "    # Filter out the last 15 minutes\n",
    "    df_filtered = df[df['Time'] <= cutoff_time].copy()\n",
    "\n",
    "    # Find peaks in the raw data for each interval\n",
    "    intervals = []\n",
    "    for start_time in range(0, int(cutoff_time), interval_seconds):\n",
    "        end_time = start_time + interval_seconds\n",
    "        interval_data = df_filtered[(df_filtered['Time'] >= start_time) & (df_filtered['Time'] < end_time)]\n",
    "        if not interval_data.empty:\n",
    "            peak_index = interval_data[column].idxmax()\n",
    "            peak_value = interval_data.loc[peak_index, column]\n",
    "            peak_time = interval_data.loc[peak_index, 'Time']\n",
    "            intervals.append((start_time, end_time, peak_value, peak_time))\n",
    "\n",
    "    # Sort intervals by peak value and get top 5\n",
    "    top_intervals = sorted(intervals, key=lambda x: x[2], reverse=True)[:5]\n",
    "\n",
    "    # Convert seconds to HH:MM:SS format\n",
    "    def seconds_to_hms(seconds):\n",
    "        return f\"{int(seconds//3600):02d}:{int((seconds%3600)//60):02d}:{int(seconds%60):02d}\"\n",
    "\n",
    "    # Function to determine which segment a time belongs to\n",
    "    def get_segment(time):\n",
    "        for i, (start, end) in enumerate(segments):\n",
    "            if start <= time < end:\n",
    "                return segment_labels[i]\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Create a DataFrame for the table\n",
    "    df_table = pd.DataFrame(top_intervals, columns=['Start', 'End', 'Peak Value', 'Peak Time'])\n",
    "    df_table['Start'] = df_table['Start'].apply(seconds_to_hms)\n",
    "    df_table['End'] = df_table['End'].apply(seconds_to_hms)\n",
    "    df_table['Peak Time'] = df_table['Peak Time'].apply(seconds_to_hms)\n",
    "    df_table['Peak Value'] = df_table['Peak Value'].apply(lambda x: f\"{x:.4f}\")\n",
    "    df_table['Segment'] = df_table['Peak Time'].apply(lambda x: get_segment(sum(int(i) * 60 ** j for j, i in enumerate(reversed(x.split(':'))))))\n",
    "\n",
    "    # Create a figure and axis for the table\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    # Hide axes\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Create the table\n",
    "    table = ax.table(cellText=df_table.values,\n",
    "                     colLabels=df_table.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "\n",
    "    # Set font size\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "\n",
    "    # Scale the table to fit the figure\n",
    "    table.scale(1, 1.5)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(\"P6GR Top 5 Intervals of Synchrony\", fontsize=16, pad=20)\n",
    "\n",
    "    # Save the table as an image\n",
    "    plt.savefig('P6GR_top_5.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(df_filtered['Time'] / 60, df_filtered[column], label='Raw data', alpha=0.8)\n",
    "    for _, _, peak_value, peak_time in top_intervals:\n",
    "        plt.scatter([peak_time / 60], [peak_value], color='red', s=100, zorder=5)\n",
    "\n",
    "    # Add segment boundaries and labels\n",
    "    for i, (start, end) in enumerate(segments):\n",
    "        if i > 0:  # Skip the first start as it's 0\n",
    "            plt.axvline(x=start/60, color='green', linestyle='--', alpha=0.5)\n",
    "        mid_point = (start + end) / 2 / 60\n",
    "        plt.text(mid_point, plt.ylim()[0] - 0.05, segment_labels[i], ha='right', va='top', rotation=45, fontsize=10)\n",
    "\n",
    "    plt.title(f'Synchrony Analysis for Column {column} with Segments')\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Synchrony')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Adjust the bottom margin to make room for the labels\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    plt.savefig('P6GRsynchrony_line.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9338e953-fe8f-49c8-a7fc-a7071ae08a59",
   "metadata": {},
   "source": [
    "# Heat map by activity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa7518-f66e-46ca-a6cb-4c8589622dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_plot_average_synchrony_heatmap_with_labels(df, column, intervals, labels):\n",
    "    # Convert Time to seconds if it's not already\n",
    "    if df['Time'].max() < 1000:  # Assuming if max is less than 1000, it's in minutes\n",
    "        df['Time'] = df['Time'] * 60\n",
    "\n",
    "    # Calculate average synchrony for each specified interval\n",
    "    averages = []\n",
    "    for start_time, end_time in intervals:\n",
    "        interval_data = df[(df['Time'] >= start_time) & (df['Time'] < end_time)]\n",
    "        if not interval_data.empty:\n",
    "            avg_synchrony = interval_data[column].mean()\n",
    "            averages.append((start_time, end_time, avg_synchrony))\n",
    "        else:\n",
    "            averages.append((start_time, end_time, None))\n",
    "\n",
    "    # Create a DataFrame for the results\n",
    "    df_averages = pd.DataFrame(averages, columns=['Start', 'End', 'Average Synchrony'])\n",
    "    df_averages['Average Synchrony'] = df_averages['Average Synchrony'].apply(lambda x: x if x is not None else 0)\n",
    "    df_averages['Duration'] = df_averages['End'] - df_averages['Start']\n",
    "\n",
    "    # Add segment names to the DataFrame\n",
    "    df_averages['Segment Name'] = labels\n",
    "\n",
    "    # Create a new DataFrame for the CSV file\n",
    "    df_csv = pd.DataFrame({\n",
    "        'Segment Name': df_averages['Segment Name'],\n",
    "        'Segment Times': df_averages.apply(lambda row: f\"{row['Start']}-{row['End']}\", axis=1),\n",
    "        'Average Synchrony': df_averages['Average Synchrony']\n",
    "    })\n",
    "\n",
    "    # Save the new DataFrame to a CSV file\n",
    "    csv_filename = 'P6GR_segment_synchrony_data.csv'\n",
    "    df_csv.to_csv(csv_filename, index=False)\n",
    "    print(f\"New CSV file '{csv_filename}' has been created with segment names, times, and average synchrony.\")\n",
    "\n",
    "\n",
    "    print(\"Average synchrony for specified intervals:\")\n",
    "    print(df_averages.to_string(index=False))\n",
    "\n",
    "    # Create a custom colormap\n",
    "    colors = ['red','yellow', 'cyan', 'blue']\n",
    "    n_bins = 100\n",
    "    cmap = LinearSegmentedColormap.from_list('warm_to_cool', colors, N=n_bins)\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "    # Calculate total duration\n",
    "    total_duration = df_averages['Duration'].sum()\n",
    "\n",
    "    # Plot rectangles for each interval\n",
    "    for i, row in df_averages.iterrows():\n",
    "        start = row['Start']\n",
    "        duration = row['Duration']\n",
    "        synchrony = row['Average Synchrony']\n",
    "        # Normalize synchrony value to the range of the data\n",
    "        norm_synchrony = (synchrony - df_averages['Average Synchrony'].min()) / (df_averages['Average Synchrony'].max() - df_averages['Average Synchrony'].min())\n",
    "        rect = Rectangle((start, 0), duration, 1, facecolor=cmap(norm_synchrony))\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add vertical text label\n",
    "        mid_point = start + duration / 2\n",
    "        ax.text(mid_point, 0.5, labels[i], ha='center', va='center', rotation=90, fontsize=8, color='black')\n",
    "\n",
    "    # Set the limits of the plot\n",
    "    ax.set_xlim(0, total_duration)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Remove y-axis ticks\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Set x-axis ticks to show time in minutes\n",
    "    x_ticks = np.arange(0, total_duration + 1, 600)  # Every 10 minutes\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels([f'{int(x/60)}' for x in x_ticks])\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=df_averages['Average Synchrony'].min(), vmax=df_averages['Average Synchrony'].max()))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, label='Average Synchrony', orientation='vertical', aspect=30)\n",
    "    cbar.ax.yaxis.set_label_position('left')\n",
    "    cbar.ax.yaxis.labelpad = 15\n",
    "\n",
    "    plt.title('Average Synchrony By Activity')\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('P6GR_average_synchrony_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109fe38-3620-4511-a846-a8acecabb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run visuals for pair P6GR\n",
    "selected_column = \"113\"\n",
    "analyze_and_create_table_with_segments(df, selected_column, segments, exclude_last_minutes=15, interval_seconds=30)\n",
    "calculate_and_plot_average_synchrony_heatmap_with_labels(df, selected_column, segments, segment_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a205ddb-cdd7-4fee-8510-d98a28f9f318",
   "metadata": {},
   "source": [
    "# Tuesday and Friday Segment code for each pair so that any pair can be run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9213a-8ab3-4d0f-825e-91e8cb891012",
   "metadata": {},
   "source": [
    "## Tuesday Segment Labels:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84e1a9a4-92e3-4b14-8dac-91f9a6d2733a",
   "metadata": {},
   "source": [
    "segment_labels = [\n",
    "    'Intro (Hello)',\n",
    "    'Group Activity #1',\n",
    "    'Game #1 (out)',\n",
    "    'Game #1 (in)',\n",
    "    #'Game #1 (out)',\n",
    "    'Group Activity #2',\n",
    "    'Game #2 (out)',\n",
    "    'Game #2 (in)',\n",
    "    #'Game #2 (out)',\n",
    "    'Group Activity #3',\n",
    "    'Game #3 (out)',\n",
    "    'Game #3 (in)',\n",
    "    #'Game #3 (out)',\n",
    "    'Individual Activity #1',\n",
    "    'Game #4 (out)',\n",
    "    'Game #4 (in)',\n",
    "    'Game #4 (out)',\n",
    "    'Group Activity #4',\n",
    "    'Game #5 (out)',\n",
    "    'Game #5 (in)',\n",
    "    'Game #5 (out)',\n",
    "    'Group Activity #5',\n",
    "    'Individual Activity #2',\n",
    "    'Outro (Goodbye)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242476e-ccf2-4ff9-8974-6f3a41173f8a",
   "metadata": {},
   "source": [
    "## Tuesday time for each pair"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0b73559-75e1-473d-9cd5-74208601b7d9",
   "metadata": {},
   "source": [
    "P6GR\n",
    "segments = [\n",
    "    (0, 435),     # 00:00:00 - 00:07:15\n",
    "    (435, 525),  # 00:07:15 - 00:08:45\n",
    "    (525, 593), # 00:08:45 - 00:09:53 \n",
    "    (593, 695), # 00:09:53 - 00:11:35 IN\n",
    "    (695, 900), # 00:11:35 - 00:15:00\n",
    "    (900, 1207), # 00:15:00 - 00:20:07\n",
    "    (1207, 1405), # 00:20:07- 00:23:25\n",
    "    (1405, 1525), # 00:23:25 - 00:25:25 IN\n",
    "    (1525, 1640), # 00:25:25- 00:27:20\n",
    "    (1640, 1917), # 00:27:20 - 00:31:57\n",
    "    (1917, 1965), # 00:31:57 -  00:32:45\n",
    "    (1965, 2070), # 00:32:45 - 00:34:30 IN\n",
    "    (2070, 2505), # 00:34:30 -  00:41:45\n",
    "    (2505, 2893), # 00:41:45 - 00:48:13\n",
    "    (2893, 3202), # 00:48:13 - 00:53:22\n",
    "    (3202, 3285), # 00:53:22 - 00:54:45 IN\n",
    "    (3285, 3378), # 00:54:45 - 00:56:18\n",
    "    (3378, 3722), # 00:56:18 - 01:02:02\n",
    "    (3722, 3860), # 01:02:02 - 01:04:20\n",
    "    (3860, 3955), # 01:04:20 - 01:05:55 IN\n",
    "    (3955, 4363), # 01:05:55 - 01:12:43\n",
    "    (4363, 4646), # 01:12:43 - 01:17:26\n",
    "    (4646, 5396), # 01:17:26 - 01:29:56\n",
    "    (5396, 5493) # 01:29:56 - 01:31:33\n",
    "]\n",
    "\n",
    "P5FR ",
    "\n",
    "segments = [\n",
    "    (0, 435),     # 00:00:00 - 00:07:15\n",
    "    (435, 525),  # 00:07:15 - 00:08:45\n",
    "    (525, 698), # 00:08:45 - 00:11:38 \n",
    "    (698, 801), # 00:11:38 - 00:13:21 IN\n",
    "    (801, 900), # 00:13:21 - 00:15:00\n",
    "    (900, 1207), # 00:15:00 - 00:20:07\n",
    "    (1207, 1283), # 00:20:07- 00:21:23\n",
    "    (1283, 1505), # 00:21:23 - 00:25:05 IN\n",
    "    (1505, 1640), # 00:25:05- 00:27:20\n",
    "    (1640, 1917), # 00:27:20 - 00:31:57\n",
    "    (1917, 2210), # 00:31:57 -  00:36:50\n",
    "    (2210, 2302), # 00:36:50 - 00:38:22 IN\n",
    "    (2302, 2505), # 00:38:22 -  00:41:45\n",
    "    (2505, 2893), # 00:41:45 - 00:48:13\n",
    "    (2893, 3100), # 00:48:13 - 00:51:40\n",
    "    (3100, 3195), # 00:51:40 - 00:53:15 IN\n",
    "    (3195, 3378), # 00:53:15 - 00:56:18\n",
    "    (3378, 3722), # 00:56:18 - 01:02:02\n",
    "    (3722, 4038), # 01:02:02 - 01:07:18\n",
    "    (4038, 4125), # 01:07:18 - 01:08:45 IN\n",
    "    (4125, 4363), # 01:08:45 - 01:12:43\n",
    "    (4363, 4646), # 01:12:43 - 01:17:26\n",
    "    (4646, 5396), # 01:17:26 - 01:29:56\n",
    "    (5396, 5493) # 01:29:56 - 01:31:33\n",
    "]\n",
    "\n",
    "P1ER  ",
    "\n",
    "segments = [\n",
    "    (0, 435),     # 00:00:00 - 00:07:15\n",
    "    (435, 525),  # 00:07:15 - 00:08:45\n",
    "    (525, 698), # 00:08:45 - 00:11:38 \n",
    "    (698, 801), # 00:11:38 - 00:13:21 IN\n",
    "    (801, 900), # 00:13:21 - 00:15:00\n",
    "    (900, 1207), # 00:15:00 - 00:20:07\n",
    "    (1207, 1530), # 00:20:07- 00:25:30\n",
    "    (1530, 1640), # 00:25:30 - 00:27:20 IN\n",
    "    #(1505, 1640), # 00:25:05- 00:27:20\n",
    "    (1640, 1917), # 00:27:20 - 00:31:57\n",
    "    (1917, 2140), # 00:31:57 -  00:35:40\n",
    "    (2140, 2210), # 00:35:40 - 00:36:50 IN\n",
    "    (2210, 2505), # 00:36:50 -  00:41:45\n",
    "    (2505, 2893), # 00:41:45 - 00:48:13\n",
    "    (2893, 2968), # 00:48:13 - 00:49:28\n",
    "    (2968, 3100), # 00:49:28 - 00:51:40 IN\n",
    "    (3100, 3378), # 00:51:40 - 00:56:18\n",
    "    (3378, 3722), # 00:56:18 - 01:02:02\n",
    "    (3722, 4125), # 01:02:02 - 01:08:45\n",
    "    (4125, 4236), # 01:08:45 - 01:10:36 IN\n",
    "    (4236, 4363), # 01:10:36 - 01:12:43\n",
    "    (4363, 4646), # 01:12:43 - 01:17:26\n",
    "    (4646, 5396), # 01:17:26 - 01:29:56\n",
    "    (5396, 5493) # 01:29:56 - 01:31:33\n",
    "]\n",
    "\n",
    "P2CR \n",
    "segments = [\n",
    "    (0, 435),     # 00:00:00 - 00:07:15\n",
    "    (435, 525),  # 00:07:15 - 00:08:45\n",
    "    (525, 807), # 00:08:45 - 00:13:27 \n",
    "    (807, 900), # 00:13:27 - 00:15:00 IN\n",
    " #  (695, 900), # 00:11:35 - 00:15:00\n",
    "    (900, 1207), # 00:15:00 - 00:20:07\n",
    "    (1207, 1283), # 00:20:07- 00:21:23\n",
    "    (1283, 1505), # 00:21:23 - 00:25:05 IN\n",
    "    (1505, 1640), # 00:25:05- 00:27:20\n",
    "    (1640, 1917), # 00:27:20 - 00:31:57\n",
    "    (1917, 2070), # 00:31:57 -  00:34:30\n",
    "    (2070, 2140), # 00:34:30 - 00:35:40 IN\n",
    "    (2140, 2505), # 00:35:40 -  00:41:45\n",
    "    (2505, 2893), # 00:41:45 - 00:48:13\n",
    "    (2893, 3100), # 00:48:13 - 00:51:40\n",
    "    (3100, 3195), # 00:51:40 - 00:53:15 IN\n",
    "    (3195, 3378), # 00:53:15 - 00:56:18\n",
    "    (3378, 3722), # 00:56:18 - 01:02:02\n",
    "    (3722, 3955), # 01:02:02 - 01:05:55\n",
    "    (3955, 4038), # 01:05:55 - 01:07:18 IN\n",
    "    (4038, 4363), # 01:07:18 - 01:12:43\n",
    "    (4363, 4646), # 01:12:43 - 01:17:26\n",
    "    (4646, 5396), # 01:17:26 - 01:29:56\n",
    "    (5396, 5493) # 01:29:56 - 01:31:33\n",
    "]\n",
    "\n",
    "P3HR\n",
    "segments = [\n",
    "    (0, 435),     # 00:00:00 - 00:07:15\n",
    "    (435, 525),  # 00:07:15 - 00:08:45\n",
    "    (525, 807), # 00:08:45 - 00:13:27 \n",
    "    (807, 900), # 00:13:27 - 00:15:00 IN\n",
    " #  (695, 900), # 00:11:35 - 00:15:00\n",
    "    (900, 1207), # 00:15:00 - 00:20:07\n",
    "    (1207, 1530), # 00:20:07- 00:21:23\n",
    "    (1530, 1640), # 00:25:30 - 00:27:20 IN\n",
    "  # (1505, 1640), # 00:25:05- 00:27:20\n",
    "    (1640, 1917), # 00:27:20 - 00:31:57\n",
    "    (1917, 2415), # 00:31:57 -  00:40:15\n",
    "    (2415, 2505), # 00:40:15 - 00:41:45 IN\n",
    "  # (2140, 2505), # 00:35:40 -  00:41:45\n",
    "    (2505, 2893), # 00:41:45 - 00:48:13\n",
    "    (2893, 3202), # 00:48:13 - 00:53:22\n",
    "    (3202, 3285), # 00:53:22 - 00:54:45 IN\n",
    "    (3285, 3378), # 00:54:45 - 00:56:18\n",
    "    (3378, 3722), # 00:56:18 - 01:02:02\n",
    "    (3722, 4236), # 01:02:02 - 01:10:36\n",
    "    (4236, 4354), # 01:10:36 - 01:12:34  IN\n",
    "    (4354, 4363), # 01:12:34 - 01:12:43\n",
    "    (4363, 4646), # 01:12:43 - 01:17:26\n",
    "    (4646, 5396), # 01:17:26 - 01:29:56\n",
    "    (5396, 5493) # 01:29:56 - 01:31:33\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68856071-c81a-4dff-971d-613120831dc2",
   "metadata": {},
   "source": [
    "# Friday segment labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "314f0d02-5a60-452b-a70e-c39f107f145c",
   "metadata": {},
   "source": [
    "segment_labels = [\n",
    "    'Intro (Hello)',\n",
    "    'Group Activity #1',\n",
    "    'Game #1 (out)',\n",
    "    'Game #1 (in)',\n",
    "    'Game #1 (out)',\n",
    "    'Group Activity #2',\n",
    "    'Group Activity #3',\n",
    "    'Game #2 (out)',\n",
    "    'Game #2 (in)',\n",
    "    'Game #2 (out)',\n",
    "    'Group Activity #4',\n",
    "    'Game #3 (out)',\n",
    "    'Game #3 (in)',\n",
    "    'Game #3 (out)',\n",
    "    'Individual Activity #1',\n",
    "    'Game #4 (out)',\n",
    "    'Game #4 (in)',\n",
    "    'Game #4 (out)',\n",
    "    'Group Activity #5',\n",
    "    'Group Activity #6',\n",
    "    'Game #5 (out)',\n",
    "    'Game #5 (in)',\n",
    "    'Game #5 (out)',\n",
    "    'Group Activity #7',\n",
    "    'Individual Activity #2',\n",
    "    'Outro (Goodbye)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc4b5d-2723-47bf-b15d-e99ceecde63a",
   "metadata": {},
   "source": [
    "## Friday time for each pair"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76bbe9d7-3748-4cad-a592-198214758d32",
   "metadata": {},
   "source": [
    "P7CR\n",
    "segments = [\n",
    "    (0, 345),     # 00:00:00 - 00:05:45 hello\n",
    "    (345, 420),  # 00:05:45 - 00:07:00 we fly\n",
    "    (420, 565), # 00:07:00 -00:9:25 game #1 out \n",
    "    (565, 660), # 00:9:25 - 00:11:00 game #1 IN\n",
    "    (660, 755), # 00:11:00 - 00:12:35 game #1 out \n",
    "    (755, 853), # 00:12:35 - 00:14:13 group activity #2\n",
    "    (853, 1170), # 00:14:34 - 00:19:30 Group activity #3\n",
    "    (1170, 1258), # 00:19:30 - 00:20:58 game #2 out \n",
    "    (1258, 1432), # 00:20:58- 00:23:52 game #2 in \n",
    "    (1432, 1627), # 00:23:52 - 00:27:07 game #2 out \n",
    "    (1627, 1870), # 00:00:27:07 - 00:31:10 Group activity #4\n",
    "    (1870, 1995), # 00:31:10 - 00:33:15 game #3 out \n",
    "    (1995, 2074), # 00:33:15 - 00:34:34 game #3 IN\n",
    "    (2074, 2290), # 00:34:34 - 00:38:10 game #3 out \n",
    "    (2290, 2598), # 00:38:10 - 00:43:18 Individual activity #1\n",
    "    (2598, 2724), # 00:43:18 - 00:45:24 game #4 out \n",
    "    (2724, 2825), # 00:45:24 -  00:47:05 game #4 in \n",
    "    # (2825, 2825), # 00:47:05- 00:47:05 game #4 out \n",
    "    (2825, 2953), # 00:47:05 - 00:49:13 group activity #5 \n",
    "    (2953, 3173), # 00:49:13 - 00:52:53 group activity #6\n",
    "    (3173, 3413), # 00:52:53 - 00:56:53 game #5 out \n",
    "    (3413, 3493), #  00:56:53 - 00:58:13 game #5 in \n",
    "    (3493, 3695), #  00:58:13 - 01:01:35 game #5 out \n",
    "    (3695, 3858), # 01:01:35 - 01:04:18 group activity #7\n",
    "    (3858, 4441) # 01:04:18 - 01:14:01 individual #2\n",
    "    (4441, 4551) # 01:14:01 - 01:15:51 Goodbye\n",
    "]\n",
    "\n",
    "\n",
    "P11ER\n",
    "segments = [\n",
    "    (0, 345),     # 00:00:00 - 00:05:45 hello\n",
    "    (345, 420),  # 00:05:45 - 00:07:00 we fly\n",
    "    (420, 660), # 00:07:00 -00:11:00 game #1 out \n",
    "    (660, 755), # 00:11:00 - 00:12:35 game #1 IN\n",
    " #(660, 755), # 00:11:00 - 00:12:35 game #1 out \n",
    "    (755, 853), # 00:12:35 - 00:14:13 group activity #2\n",
    "    (853, 1170), # 00:14:34 - 00:19:30 Group activity #3\n",
    "    (1170, 1540), # 00:19:30 - 00:25:40 game #2 out \n",
    "    (1540, 1627), # 00:25:40 - 00:27:07 game #2 in \n",
    "  #(1432, 1627), # 00:23:52 - 00:27:07 game #2 out \n",
    "    (1627, 1870), # 00:00:27:07 - 00:31:10 Group activity #4\n",
    "    (1870, 2160), # 00:31:10 - 00:36:00 game #3 out \n",
    "    (2160, 2237), # 00:36:00 - 00:37:17 game #3 IN\n",
    "    (2237, 2290), # 00:37:17 - 00:38:10 game #3 out \n",
    "    (2290, 2598), # 00:38:10 - 00:43:18 Individual activity #1\n",
    "    (2598, 2655), # 00:43:18 - 00:44:15 game #4 out \n",
    "    (2655, 2724), # 00:44:15 - 00:45:24 game #4 in \n",
    "    (2724, 2825), # 00:45:24- 00:47:05 game #4 out \n",
    "    (2825, 2953), # 00:47:05 - 00:49:13 group activity #5 \n",
    "    (2953, 3173), # 00:49:13 - 00:52:53 group activity #6\n",
    "    (3173, 3493), # 00:52:53 - 00:58:13 game #5 out \n",
    "    (3493, 3603), #  00:58:13 - 01:00:03 game #5 in \n",
    "    (3603, 3695), #  01:00:03 - 01:01:35 game #5 out \n",
    "    (3695, 3858), # 01:01:35 - 01:04:18 group activity #7\n",
    "    (3858, 4441) # 01:04:18 - 01:14:01 individual #2\n",
    "    (4441, 4551) # 01:14:01 - 01:15:51 Goodbye\n",
    "]\n",
    "\n",
    "P8IR\n",
    "segments = [\n",
    "    (0, 345),     # 00:00:00 - 00:05:45 hello\n",
    "    (345, 420),  # 00:05:45 - 00:07:00 we fly\n",
    "    (420, 565), # 00:07:00 -00:9:25 game #1 out \n",
    "    (565, 660), # 00:9:25 - 00:11:00 game #1 IN\n",
    "    (660, 755), # 00:11:00 - 00:12:35 game #1 out \n",
    "    (755, 853), # 00:12:35 - 00:14:13 group activity #2\n",
    "    (853, 1170), # 00:14:34 - 00:19:30 Group activity #3\n",
    "    (1170, 1432), # 00:19:30 - 00:23:52 game #2 out \n",
    "    (1432, 1540), # 00:23:52 - 00:25:40 game #2 in \n",
    "    (1540, 1627), # 00:25:40 - 00:27:07 game #2 out \n",
    "    (1627, 1870), # 00:00:27:07 - 00:31:10 Group activity #4\n",
    "    (1870, 2237), # 00:31:10 - 00:37:17 game #3 out \n",
    "    (2237, 2290), # 00:37:17 - 38:10 game #3 IN\n",
    "    #(2237, 2290), # 00:37:17 - 00:38:10 game #3 out \n",
    "    (2290, 2598), # 00:38:10 - 00:43:18 Individual activity #1\n",
    "    (2598, 2825), # 00:43:18 - 00:47:05 game #4 out \n",
    "    #(2655, 2724), # 00:44:15 - 00:45:24 game #4 in \n",
    "    #(2724, 2825), # 00:45:24- 00:47:05 game #4 out \n",
    "    (2825, 2953), # 00:47:05 - 00:49:13 group activity #5 \n",
    "    (2953, 3173), # 00:49:13 - 00:52:53 group activity #6\n",
    "    (3173, 3603), # 00:52:53 - 01:00:03 game #5 out \n",
    "    (3603, 3695), #  01:00:03 - 01:01:35 game #5 in \n",
    "    #(3603, 3695), #  01:00:03 - 01:01:35 game #5 out \n",
    "    (3695, 3858), # 01:01:35 - 01:04:18 group activity #7\n",
    "    (3858, 4441) # 01:04:18 - 01:14:01 individual #2\n",
    "    (4441, 4551) # 01:14:01 - 01:15:51 Goodbye\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
